import numpy as np
from scipy.spatial.distance import cdist
import scipy.stats as stats
from sklearn.neighbors import KernelDensity
from sklearn.mixture import GaussianMixture
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.kernel_ridge import KernelRidge
from sklearn.kernel_approximation import RBFSampler, Nystroem
from sklearn.linear_model import Ridge
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import optuna
from tqdm import tqdm
import warnings

try:
    import jax
    import jax.numpy as jnp
    from jax import jit, vmap
    JAX_AVAILABLE = True
except ImportError:
    JAX_AVAILABLE = False

from time import time    

class DistroSimulator:
    def __init__(self, kernel='rbf', backend='numpy', n_clusters=5, 
                 clustering_method='kmeans', random_state=None,
                 residual_sampling='bootstrap', kde_bandwidth=1.0, 
                 gmm_components=3, use_rff='auto', rff_components='auto',
                 rff_gamma=None, kernel_approximation='rff',
                 force_rff_threshold=1000):
        """
        Initialize the multivariate data generator.
        
        Parameters:
        -----------
        kernel : str, default='rbf'
            Kernel type for KernelRidge regression
        backend : str, default='numpy'
            Backend for distance calculations ('numpy', 'gpu', 'tpu')
        n_clusters : int, default=5
            Number of clusters for stratified splitting
        clustering_method : str, default='kmeans'
            Clustering method for stratification ('kmeans' or 'gmm')
        random_state : int, default=None
            Random seed for reproducibility
        residual_sampling : str, default='bootstrap'
            Method for sampling residuals ('bootstrap', 'kde', 'gmm')
        kde_bandwidth : float, default=1.0
            Bandwidth for KDE sampling
        gmm_components : int, default=3
            Number of components for GMM sampling
        use_rff : bool or 'auto', default='auto'
            Whether to use kernel approximation. 'auto' enables for large datasets
        rff_components : int or 'auto', default='auto'
            Number of approximation components. 'auto' chooses based on data size
        rff_gamma : float, default=None
            Gamma parameter for approximation. If None, will be tuned.
        kernel_approximation : str, default='rff'
            Approximation method ('rff' or 'nystroem')
        force_rff_threshold : int, default=1000
            Auto-enable RFF when n_samples exceeds this threshold
        """
        self.kernel = kernel
        self.backend = backend
        self.n_clusters = n_clusters
        self.clustering_method = clustering_method
        self.random_state = random_state
        self.residual_sampling = residual_sampling
        self.kde_bandwidth = kde_bandwidth
        self.gmm_components = gmm_components
        self.use_rff = use_rff
        self.rff_components = rff_components
        self.rff_gamma = rff_gamma
        self.kernel_approximation = kernel_approximation
        self.force_rff_threshold = force_rff_threshold
        
        if random_state is not None:
            np.random.seed(random_state)
            if JAX_AVAILABLE:
                key = jax.random.PRNGKey(random_state)
        
        # Validate sampling method
        valid_sampling_methods = ['bootstrap', 'kde', 'gmm']
        if residual_sampling not in valid_sampling_methods:
            raise ValueError(f"residual_sampling must be one of {valid_sampling_methods}")
        
        # Validate approximation method
        valid_approximations = ['rff', 'nystroem']
        if kernel_approximation not in valid_approximations:
            raise ValueError(f"kernel_approximation must be one of {valid_approximations}")
        
        # Initialize JAX if using GPU/TPU backend
        if backend in ['gpu', 'tpu'] and JAX_AVAILABLE:
            self._setup_jax_backend()
        elif backend in ['gpu', 'tpu'] and not JAX_AVAILABLE:
            print("JAX not available. Falling back to NumPy backend.")
            self.backend = 'numpy'
        
        # Initialize attributes that will be set during fitting
        self.model = None
        self.residuals = None
        self.X_dist = None
        self.is_fitted = False
        self.best_params_ = None
        self.best_score_ = None
        self.cluster_labels_ = None
        self.cluster_model_ = None
        self.kde_model_ = None
        self.gmm_model_ = None
        self.scaler_ = None
        self.actual_rff_components_ = None
        self.actual_use_rff_ = None

    def _setup_jax_backend(self):
        """Setup JAX backend for GPU/TPU acceleration."""
        if not JAX_AVAILABLE:
            raise ImportError("JAX is required for GPU/TPU backend")
        
        # JIT compiled distance functions
        @jit
        def pairwise_sq_dists_jax(X1, X2):
            X1_sq = jnp.sum(X1**2, axis=1)[:, jnp.newaxis]
            X2_sq = jnp.sum(X2**2, axis=1)[jnp.newaxis, :]
            return X1_sq + X2_sq - 2 * X1 @ X2.T
        
        @jit
        def cdist_jax(X1, X2):
            return vmap(lambda x: vmap(lambda y: jnp.sqrt(jnp.sum((x - y)**2)))(X2))(X1)
        
        self._pairwise_sq_dists_jax = pairwise_sq_dists_jax
        self._cdist_jax = cdist_jax

    def _determine_components(self, n_samples, n_features):
        """Automatically determine optimal number of components."""
        if self.rff_components == 'auto':
            # Optimized heuristic based on performance results
            if n_samples < 500:
                return min(50, n_samples)
            elif n_samples < 2000:
                return min(100, n_samples // 2)
            elif n_samples < 5000:
                return min(150, n_samples // 3)
            elif n_samples < 10000:
                return min(200, n_samples // 4)
            else:
                return min(300, n_samples // 5)
        else:
            return self.rff_components

    def _create_model(self, gamma, alpha, use_rff=None):
        """Create the appropriate model based on RFF setting."""
        if use_rff is None:
            use_rff = self.actual_use_rff_
        
        if use_rff:
            # Use kernel approximation with Ridge regression
            if self.rff_gamma is not None:
                effective_gamma = self.rff_gamma
            else:
                effective_gamma = gamma
            
            # Determine number of components
            n_components = self.actual_rff_components_
            
            if self.kernel_approximation == 'rff':
                approximator = RBFSampler(
                    gamma=effective_gamma,
                    n_components=n_components,
                    random_state=self.random_state
                )
            else:  # nystroem
                approximator = Nystroem(
                    kernel='rbf',
                    gamma=effective_gamma,
                    n_components=n_components,
                    random_state=self.random_state
                )
            
            # Create pipeline with scaling, approximation, and Ridge
            pipeline = Pipeline([
                ('scaler', StandardScaler()),
                ('approx', approximator),
                ('ridge', Ridge(alpha=alpha))
            ])
            return pipeline
        else:
            # Standard KernelRidge
            return KernelRidge(kernel=self.kernel, gamma=gamma, alpha=alpha)

    def _fit_residual_sampler(self):
        """Fit the chosen residual sampling model."""
        if self.residuals is None or len(self.residuals) == 0:
            raise ValueError("No residuals available for fitting sampler")
        
        if self.residual_sampling == 'kde':
            self.kde_model_ = KernelDensity(
                bandwidth=self.kde_bandwidth,
                kernel='gaussian'
            )
            self.kde_model_.fit(self.residuals)
            print(f"Fitted KDE sampler with bandwidth {self.kde_bandwidth}")
            
        elif self.residual_sampling == 'gmm':
            self.gmm_model_ = GaussianMixture(
                n_components=min(self.gmm_components, len(self.residuals)),
                random_state=self.random_state,
                covariance_type='full'
            )
            self.gmm_model_.fit(self.residuals)
            print(f"Fitted GMM sampler with {self.gmm_components} components")

    def _sample_residuals(self, num_samples):
        """Sample residuals using the chosen method."""
        if self.residuals is None:
            raise ValueError("No residuals available for sampling")
        
        if self.residual_sampling == 'bootstrap':
            # Original bootstrap method
            n = self.residuals.shape[0]
            idx = np.random.choice(n, num_samples, replace=True)
            return self.residuals[idx]
        
        elif self.residual_sampling == 'kde':
            # Kernel Density Estimation sampling
            if self.kde_model_ is None:
                raise ValueError("KDE model not fitted. Call _fit_residual_sampler first.")
            
            # Sample from KDE
            samples = self.kde_model_.sample(num_samples)
            return samples.reshape(-1, self.residuals.shape[1])
        
        elif self.residual_sampling == 'gmm':
            # Gaussian Mixture Model sampling
            if self.gmm_model_ is None:
                raise ValueError("GMM model not fitted. Call _fit_residual_sampler first.")
            
            # Sample from GMM
            samples, _ = self.gmm_model_.sample(num_samples)
            return samples
        
        else:
            raise ValueError(f"Unknown sampling method: {self.residual_sampling}")

    def _pairwise_sq_dists(self, X1, X2):
        """Compute pairwise squared Euclidean distances."""
        if self.backend in ['gpu', 'tpu'] and JAX_AVAILABLE:
            X1_jax = jnp.array(X1)
            X2_jax = jnp.array(X2)
            result = self._pairwise_sq_dists_jax(X1_jax, X2_jax)
            return np.array(result)
        else:
            X1 = np.atleast_2d(X1)
            X2 = np.atleast_2d(X2)
            return np.sum(X1**2, axis=1)[:, np.newaxis] + np.sum(X2**2, axis=1)[np.newaxis, :] - 2 * X1 @ X2.T

    def _compute_clusters(self, Y):
        """Compute cluster labels for stratified splitting."""
        if self.clustering_method == 'kmeans':
            cluster_model = KMeans(n_clusters=self.n_clusters, 
                                 random_state=self.random_state,
                                 n_init=10)
        elif self.clustering_method == 'gmm':
            cluster_model = GaussianMixture(n_components=self.n_clusters, 
                                          random_state=self.random_state)
        else:
            raise ValueError("clustering_method must be 'kmeans' or 'gmm'")
        
        cluster_model.fit(Y)
        self.cluster_model_ = cluster_model
        return cluster_model.predict(Y)

    def _stratified_train_test_split(self, Y, n_train):
        """Create stratified train-test split based on clusters."""
        if n_train >= len(Y):
            raise ValueError("n_train must be less than the number of samples")
        
        # Compute clusters
        self.cluster_labels_ = self._compute_clusters(Y)
        
        # Perform stratified split
        train_idx, test_idx = train_test_split(
            np.arange(len(Y)),
            train_size=n_train,
            stratify=self.cluster_labels_,
            random_state=self.random_state
        )
        
        return train_idx, test_idx

    def _mmd(self, u, v, kernel_sigma=1):
        """Maximum Mean Discrepancy between two distributions."""
        if u.ndim == 1:
            u = u.reshape(-1, 1)
        if v.ndim == 1:
            v = v.reshape(-1, 1)
        
        def kmat(A, B):
            return np.exp(-self._pairwise_sq_dists(A, B) / (2 * kernel_sigma**2))
        
        return np.mean(kmat(u, u)) + np.mean(kmat(v, v)) - 2 * np.mean(kmat(u, v))

    def _custom_energy_distance(self, u, v):
        """Energy distance between two distributions."""
        if u.ndim == 1:
            u = u.reshape(-1, 1)
        if v.ndim == 1:
            v = v.reshape(-1, 1)
        
        n, d = u.shape
        m = v.shape[0]
        
        if self.backend in ['gpu', 'tpu'] and JAX_AVAILABLE:
            # JAX implementation
            u_jax = jnp.array(u)
            v_jax = jnp.array(v)
            
            dist_xx = self._cdist_jax(u_jax, u_jax)
            dist_yy = self._cdist_jax(v_jax, v_jax)
            dist_xy = self._cdist_jax(u_jax, v_jax)
            
            term1 = 2 * jnp.sum(dist_xy) / (n * m)
            term2 = jnp.sum(dist_xx) / (n * n)
            term3 = jnp.sum(dist_yy) / (m * m)
            
            return float(term1 - term2 - term3)
        else:
            # NumPy implementation
            dist_xx = cdist(u, u, metric='euclidean')
            dist_yy = cdist(v, v, metric='euclidean')
            dist_xy = cdist(u, v, metric='euclidean')
            
            term1 = 2 * np.sum(dist_xy) / (n * m)
            term2 = np.sum(dist_xx) / (n * n)
            term3 = np.sum(dist_yy) / (m * m)
            return term1 - term2 - term3

    def _generate_pseudo(self, num_samples):
        """Generate synthetic data using the fitted model and residuals."""
        if not self.is_fitted:
            raise ValueError("Model not fitted. Call fit() first.")
        
        X_new = self.X_dist(num_samples)
        
        # Handle prediction based on model type
        if self.actual_use_rff_:
            # For RFF pipeline
            preds = self.model.predict(X_new)
        else:
            # For standard KernelRidge
            preds = self.model.predict(X_new)
            
        if preds.ndim == 1:
            preds = preds.reshape(-1, 1)
        
        # Sample residuals using the chosen method
        e_star = self._sample_residuals(num_samples)
        
        return preds + e_star

    def fit(self, Y, X_dist, n_train=None, metric='energy', n_trials=50, **kwargs):
        """
        Fit the data generator to match the distribution of Y.
        
        Parameters:
        -----------
        Y : array-like, shape (n_samples, n_features)
            Target multivariate data to emulate
        X_dist : callable
            Function that takes n_samples and returns input data X
        n_train : int, default=None
            Number of training samples (default: n_samples // 2)
        metric : str, default='energy'
            Distance metric for optimization ('energy', 'mmd', or 'wasserstein')
        n_trials : int, default=50
            Number of Optuna optimization trials
        **kwargs : dict
            Additional arguments for Optuna optimization
        
        Returns:
        --------
        self : object
            Returns self
        """
        if Y.ndim == 1:
            Y = Y.reshape(-1, 1)
        
        n, d = Y.shape
        self.n_features_ = d
        
        # Determine whether to use RFF
        if self.use_rff == 'auto':
            self.actual_use_rff_ = n >= self.force_rff_threshold
        else:
            self.actual_use_rff_ = self.use_rff
        
        # Auto-enable RFF for large datasets with component determination
        if self.actual_use_rff_:
            self.actual_rff_components_ = self._determine_components(n, d)
            if self.use_rff == 'auto':
                print(f"Large dataset detected (n={n}). Auto-enabling {self.kernel_approximation.upper()} for scalability.")
        
        if n_train is None:
            n_train = n // 2
        
        # Store the input distribution function
        self.X_dist = X_dist
        
        # Create stratified train-test split
        train_idx, test_idx = self._stratified_train_test_split(Y, n_train)
        Y_train = Y[train_idx]
        Y_test = Y[test_idx]
        X_train = X_dist(n_train)
        
        print(f"Stratified split: {len(train_idx)} train, {len(test_idx)} test samples")
        print(f"Residual sampling method: {self.residual_sampling}")
        print(f"Using {self.kernel_approximation.upper()}: {self.actual_use_rff_}")
        if self.actual_use_rff_:
            print(f"Components: {self.actual_rff_components_}")
            print(f"Approximation method: {self.kernel_approximation}")
        if self.residual_sampling == 'kde':
            print(f"KDE bandwidth: {self.kde_bandwidth}")
        elif self.residual_sampling == 'gmm':
            print(f"GMM components: {self.gmm_components}")
        
        def objective(trial):
            sigma = trial.suggest_float('sigma', 0.01, 10, log=True)
            lambd = trial.suggest_float('lambd', 1e-5, 1, log=True)
            gamma = 1 / (2 * sigma**2)
            
            # Create model with current parameters
            model = self._create_model(gamma, lambd)
            model.fit(X_train, Y_train)
            
            preds_train = model.predict(X_train)
            if preds_train.ndim == 1:
                preds_train = preds_train.reshape(-1, 1)
            
            res = Y_train - preds_train
            Y_sim = self._generate_pseudo_with_model(model, res, len(Y_test))
            
            if metric == 'energy':
                dist_val = self._custom_energy_distance(Y_test, Y_sim)
            elif metric == 'mmd':
                dist_val = self._mmd(Y_test, Y_sim)
            elif metric == 'wasserstein' and d == 1:
                dist_val = stats.wasserstein_distance(Y_test.flatten(), Y_sim.flatten())
            else:
                raise ValueError("Invalid metric for dimension")
            
            return dist_val
        
        # Optimize hyperparameters
        study = optuna.create_study(direction='minimize')
        study.optimize(objective, n_trials=n_trials, **kwargs)
        
        # Store best parameters and fit final model
        self.best_params_ = study.best_params
        self.best_score_ = study.best_value
        
        sigma = self.best_params_['sigma']
        lambd = self.best_params_['lambd']
        gamma = 1 / (2 * sigma**2)
        
        # Fit final model with best parameters
        self.model = self._create_model(gamma, lambd)
        self.model.fit(X_train, Y_train)
        
        # Compute residuals
        preds_train = self.model.predict(X_train)
        if preds_train.ndim == 1:
            preds_train = preds_train.reshape(-1, 1)
        self.residuals = Y_train - preds_train
        
        # Fit the residual sampler
        self._fit_residual_sampler()
        
        self.is_fitted = True
        
        # Print final configuration
        print(f"\nFinal configuration:")
        print(f"  Best score: {self.best_score_:.6f}")
        print(f"  Best sigma: {sigma:.4f}")
        print(f"  Best lambda: {lambd:.6f}")
        if self.actual_use_rff_:
            print(f"  Using {self.kernel_approximation.upper()} with {self.actual_rff_components_} components")
        else:
            print(f"  Using standard kernel method")
        
        return self

    def _generate_pseudo_with_model(self, model, residuals, num_samples):
        """Helper method to generate data with a specific model."""
        X_new = self.X_dist(num_samples)
        
        # Handle prediction based on model type
        if hasattr(model, 'named_steps') and 'rff' in model.named_steps:
            # RFF pipeline
            preds = model.predict(X_new)
        else:
            # Standard model
            preds = model.predict(X_new)
            
        if preds.ndim == 1:
            preds = preds.reshape(-1, 1)
        
        # Temporarily store residuals and fit sampler for this model
        original_residuals = self.residuals
        original_sampling = self.residual_sampling
        
        self.residuals = residuals
        self._fit_residual_sampler()
        
        # Sample residuals
        e_star = self._sample_residuals(num_samples)
        
        # Restore original state
        self.residuals = original_residuals
        if original_sampling == 'kde':
            self._fit_residual_sampler()  # Refit original KDE
        elif original_sampling == 'gmm':
            self._fit_residual_sampler()  # Refit original GMM
        
        return preds + e_star

    def sample(self, n_samples=1):
        """
        Generate synthetic samples.
        
        Parameters:
        -----------
        n_samples : int, default=1
            Number of samples to generate
            
        Returns:
        --------
        Y_sim : array, shape (n_samples, n_features)
            Generated synthetic data
        """
        if not self.is_fitted:
            raise ValueError("Model not fitted. Call fit() first.")
        
        return self._generate_pseudo(n_samples)

    def compare_approximation_methods(self, Y, X_dist, n_train=None, n_trials=20):
        """
        Compare different kernel approximation methods.
        
        Parameters:
        -----------
        Y : array-like
            Target data
        X_dist : callable
            Input distribution function
        n_train : int, default=None
            Number of training samples
        n_trials : int, default=20
            Number of optimization trials
            
        Returns:
        --------
        comparison_results : dict
            Comparison results
        """
        if Y.ndim == 1:
            Y = Y.reshape(-1, 1)
        
        print("Comparing Kernel Approximation Methods...")
        
        # Store original settings
        original_use_rff = self.use_rff
        original_approximation = self.kernel_approximation
        original_is_fitted = self.is_fitted
        
        methods = ['rff', 'nystroem']
        results = {}
        
        for method in methods:
            print(f"\nTesting {method.upper()}...")
            self.use_rff = True
            self.kernel_approximation = method
            
            start_time = time()
            self.fit(Y, X_dist, n_train=n_train, n_trials=n_trials)
            method_time = time() - start_time
            method_score = self.best_score_
            method_params = self.best_params_
            
            results[method] = {
                'time': method_time,
                'score': method_score,
                'params': method_params,
                'components': self.actual_rff_components_
            }
        
        # Test standard method for comparison
        print(f"\nTesting Standard Kernel...")
        self.use_rff = False
        start_time = time()
        self.fit(Y, X_dist, n_train=n_train, n_trials=n_trials)
        standard_time = time() - start_time
        standard_score = self.best_score_
        standard_params = self.best_params_
        
        results['standard'] = {
            'time': standard_time,
            'score': standard_score,
            'params': standard_params,
            'components': 'N/A'
        }
        
        # Restore original settings
        self.use_rff = original_use_rff
        self.kernel_approximation = original_approximation
        self.is_fitted = original_is_fitted
        
        # Print comparison
        print("\n" + "="*60)
        print("KERNEL APPROXIMATION COMPARISON RESULTS")
        print("="*60)
        
        for method in ['standard'] + methods:
            data = results[method]
            print(f"\n{method.upper()}:")
            print(f"  Time: {data['time']:.2f}s")
            print(f"  Score: {data['score']:.6f}")
            print(f"  Components: {data['components']}")
            if method != 'standard':
                speedup = standard_time / data['time']
                score_ratio = data['score'] / standard_score
                print(f"  Speedup: {speedup:.2f}x")
                print(f"  Score Ratio: {score_ratio:.4f}")
        
        return results

    def compare_residual_sampling(self, n_samples=1000):
        """
        Compare different residual sampling methods visually.
        
        Parameters:
        -----------
        n_samples : int, default=1000
            Number of samples to generate for comparison
        """
        if not self.is_fitted:
            raise ValueError("Model not fitted. Call fit() first.")
        
        # Store original sampling method
        original_sampling = self.residual_sampling
        
        # Generate samples with different methods
        sampling_methods = ['bootstrap', 'kde', 'gmm']
        samples = {}
        
        for method in sampling_methods:
            self.residual_sampling = method
            if method == 'kde':
                self._fit_residual_sampler()
            elif method == 'gmm':
                self._fit_residual_sampler()
            samples[method] = self._sample_residuals(n_samples)
        
        # Restore original method
        self.residual_sampling = original_sampling
        self._fit_residual_sampler()
        
        # Plot comparison
        n_dims = self.residuals.shape[1]
        fig, axes = plt.subplots(n_dims, len(sampling_methods) + 1, 
                                figsize=(5 * (len(sampling_methods) + 1), 4 * n_dims))
        
        if n_dims == 1:
            axes = axes.reshape(1, -1)
        
        for dim in range(n_dims):
            # Original residuals
            axes[dim, 0].hist(self.residuals[:, dim], bins=30, alpha=0.7, density=True)
            axes[dim, 0].set_title(f'Original Residuals\nDim {dim+1}')
            axes[dim, 0].set_xlabel('Residual Value')
            axes[dim, 0].set_ylabel('Density')
            
            # Sampled residuals
            for j, method in enumerate(sampling_methods):
                col = j + 1
                axes[dim, col].hist(samples[method][:, dim], bins=30, alpha=0.7, density=True)
                axes[dim, col].set_title(f'{method.upper()} Sampling\nDim {dim+1}')
                axes[dim, col].set_xlabel('Residual Value')
                axes[dim, col].set_ylabel('Density')
        
        plt.tight_layout()
        plt.show()
        
        return samples

    def _perm_test(self, Y_orig, Y_sim, stat_func, n_perm=1000):
        """Permutation test for distribution comparison."""
        if Y_orig.ndim == 1:
            Y_orig = Y_orig.reshape(-1, 1)
        if Y_sim.ndim == 1:
            Y_sim = Y_sim.reshape(-1, 1)
        
        obs = stat_func(Y_orig, Y_sim)
        combined = np.vstack((Y_orig, Y_sim))
        n1 = Y_orig.shape[0]
        perms = np.zeros(n_perm)
        
        for i in range(n_perm):
            idx = np.random.permutation(combined.shape[0])
            p1 = combined[idx[:n1]]
            p2 = combined[idx[n1:]]
            perms[i] = stat_func(p1, p2)
        
        pval = (np.sum(perms >= obs) + 1) / (n_perm + 1)
        return obs, pval

    def _fisher_z_test(self, r1, r2, n1, n2):
        """Fisher z-test for comparing correlation coefficients."""
        z1 = np.arctanh(r1)
        z2 = np.arctanh(r2)
        z = (z1 - z2) / np.sqrt(1 / (n1 - 3) + 1 / (n2 - 3))
        p = 2 * (1 - stats.norm.cdf(np.abs(z)))
        return z, p

    def test_similarity(self, Y_orig, Y_sim, n_perm=1000):
        """
        Test statistical similarity between original and synthetic data.
        
        Parameters:
        -----------
        Y_orig : array-like
            Original data
        Y_sim : array-like
            Synthetic data
        n_perm : int, default=1000
            Number of permutations for permutation tests
            
        Returns:
        --------
        results : dict
            Dictionary containing test results
        """
        if Y_orig.ndim == 1:
            Y_orig = Y_orig.reshape(-1, 1)
        if Y_sim.ndim == 1:
            Y_sim = Y_sim.reshape(-1, 1)
        
        d = Y_orig.shape[1]
        results = {}
        
        # Test 1: Perm with energy
        results['energy_perm'] = self._perm_test(Y_orig, Y_sim, self._custom_energy_distance, n_perm)
        
        # Test 2: Perm with MMD
        results['mmd_perm'] = self._perm_test(Y_orig, Y_sim, lambda u, v: self._mmd(u, v), n_perm)
        
        # Test 3: Perm with avg Wasserstein on margins
        def avg_wass(u, v):
            return np.mean([stats.wasserstein_distance(u[:, i], v[:, i]) for i in range(d)])
        results['avg_wass_perm'] = self._perm_test(Y_orig, Y_sim, avg_wass, n_perm)
        
        # Test 4: Min p-value from marginal KS tests
        ps_ks = [stats.ks_2samp(Y_orig[:, i], Y_sim[:, i]).pvalue for i in range(d)]
        results['min_marginal_ks_p'] = min(ps_ks)
        
        # Test 5: Min p-value from marginal Anderson-Darling tests
        ps_ad = [stats.anderson_ksamp([Y_orig[:, i], Y_sim[:, i]]).significance_level for i in range(d)]
        results['min_marginal_ad_p'] = min(ps_ad)
        
        # Test 6: Min p-value from marginal Cramer-von Mises tests
        ps_cvm = [stats.cramervonmises_2samp(Y_orig[:, i], Y_sim[:, i]).pvalue for i in range(d)]
        results['min_marginal_cvm_p'] = min(ps_cvm)
        
        # Correlation test: Compare all pairwise correlations
        corr_results = {}
        pairs = [(i, j) for i in range(d) for j in range(i + 1, d)]
        for i, j in pairs:
            r_orig = stats.pearsonr(Y_orig[:, i], Y_orig[:, j])[0]
            r_sim = stats.pearsonr(Y_sim[:, i], Y_sim[:, j])[0]
            z, p = self._fisher_z_test(r_orig, r_sim, len(Y_orig), len(Y_sim))
            corr_results[f'corr_dim{i+1}_dim{j+1}'] = (r_orig, r_sim, z, p)
        
        results['corr_tests'] = corr_results
        return results

    def compare_distributions(self, Y_orig, Y_sim, save_prefix=''):
        """
        Visual comparison of original and synthetic distributions.
        
        Parameters:
        -----------
        Y_orig : array-like
            Original data
        Y_sim : array-like
            Synthetic data
        save_prefix : str, default=''
            Prefix for saving plots
        """
        if Y_orig.ndim == 1:
            Y_orig = Y_orig.reshape(-1, 1)
        if Y_sim.ndim == 1:
            Y_sim = Y_sim.reshape(-1, 1)
        
        n, d = Y_orig.shape
        
        # Create a figure with subplots for statistical tests
        fig, axes = plt.subplots(2, d, figsize=(6 * d, 10))
        if d == 1:
            axes = axes.reshape(2, 1)
        
        # Statistical test results storage
        ks_results = []
        ad_results = []
        
        for i in range(d):
            # Top row: Histograms with statistical test annotations
            ax_hist = axes[0, i]
            
            # Plot histograms
            ax_hist.hist(Y_orig[:, i], alpha=0.5, label='Original', density=True, bins=20, color='blue')
            ax_hist.hist(Y_sim[:, i], alpha=0.5, label='Simulated', density=True, bins=20, color='red')
            
            # Perform statistical tests
            # Kolmogorov-Smirnov test
            ks_stat, ks_pvalue = stats.ks_2samp(Y_orig[:, i], Y_sim[:, i])
            ks_results.append((ks_stat, ks_pvalue))
            
            # Anderson-Darling test
            ad_result = stats.anderson_ksamp([Y_orig[:, i], Y_sim[:, i]])
            ad_stat = ad_result.statistic
            ad_critical = ad_result.critical_values
            ad_significance = ad_result.significance_level
            ad_results.append((ad_stat, ad_significance))
            
            # Add test results to histogram plot
            textstr = '\n'.join((
                f'KS test: p = {ks_pvalue:.4f}',
                f'AD test: p < {ad_significance:.3f}',
                f'AD stat: {ad_stat:.4f}'
            ))
            props = dict(boxstyle='round', facecolor='wheat', alpha=0.8)
            ax_hist.text(0.05, 0.95, textstr, transform=ax_hist.transAxes, fontsize=10,
                        verticalalignment='top', bbox=props)
            
            ax_hist.legend()
            ax_hist.set_title(f'Dimension {i+1} - Histograms with Statistical Tests')
            ax_hist.set_xlabel('Value')
            ax_hist.set_ylabel('Density')
            
            # Bottom row: ECDFs with KS test visualization
            ax_ecdf = axes[1, i]
            
            # Compute ECDFs
            sorted_orig = np.sort(Y_orig[:, i])
            ecdf_orig = np.arange(1, len(sorted_orig) + 1) / len(sorted_orig)
            sorted_sim = np.sort(Y_sim[:, i])
            ecdf_sim = np.arange(1, len(sorted_sim) + 1) / len(sorted_sim)
            
            # Plot ECDFs
            ax_ecdf.step(sorted_orig, ecdf_orig, label='Original', color='blue', linewidth=2)
            ax_ecdf.step(sorted_sim, ecdf_sim, label='Simulated', color='red', linewidth=2)
            
            # Find the point of maximum difference for KS test
            # Combine and sort all values
            all_values = np.sort(np.concatenate([sorted_orig, sorted_sim]))
            # Compute ECDFs at all points
            ecdf_orig_all = np.searchsorted(sorted_orig, all_values, side='right') / len(sorted_orig)
            ecdf_sim_all = np.searchsorted(sorted_sim, all_values, side='right') / len(sorted_sim)
            # Find maximum difference
            diff = np.abs(ecdf_orig_all - ecdf_sim_all)
            max_idx = np.argmax(diff)
            max_x = all_values[max_idx]
            max_y1 = ecdf_orig_all[max_idx]
            max_y2 = ecdf_sim_all[max_idx]
            
            # Mark the maximum difference point
            ax_ecdf.plot([max_x, max_x], [max_y1, max_y2], 'k-', linewidth=3, 
                        label=f'KS stat: {ks_stat:.4f}')
            ax_ecdf.plot(max_x, max_y1, 'ko', markersize=8)
            ax_ecdf.plot(max_x, max_y2, 'ko', markersize=8)
            
            ax_ecdf.legend()
            ax_ecdf.set_title(f'Dimension {i+1} - ECDFs with KS Statistic')
            ax_ecdf.set_xlabel('Value')
            ax_ecdf.set_ylabel('ECDF')
        
        plt.tight_layout()
        if save_prefix:
            plt.savefig(f'{save_prefix}_statistical_comparison.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Print comprehensive test results
        print("\n" + "="*60)
        print("COMPREHENSIVE STATISTICAL TEST RESULTS")
        print("="*60)
        
        for i in range(d):
            ks_stat, ks_pvalue = ks_results[i]
            ad_stat, ad_significance = ad_results[i]
            
            print(f"\nDimension {i+1}:")
            print(f"  Kolmogorov-Smirnov Test:")
            print(f"    Statistic: {ks_stat:.6f}")
            print(f"    p-value: {ks_pvalue:.6f}")
            print(f"    Significance: {'Not Significant' if ks_pvalue > 0.05 else 'SIGNIFICANT'}")
            
            print(f"  Anderson-Darling Test:")
            print(f"    Statistic: {ad_stat:.6f}")
            print(f"    Significance level: {ad_significance:.3f}")
            print(f"    Interpretation: {'Distributions differ' if ad_stat > ad_result.critical_values[2] else 'Distributions similar'}")
        
        # Create summary plot for all dimensions
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))
        
        # KS test p-values across dimensions
        ks_pvalues = [result[1] for result in ks_results]
        dimensions = list(range(1, d + 1))
        
        bars = ax1.bar(dimensions, ks_pvalues, color=['red' if p < 0.05 else 'green' for p in ks_pvalues])
        ax1.axhline(y=0.05, color='black', linestyle='--', alpha=0.7, label='α = 0.05')
        ax1.set_xlabel('Dimension')
        ax1.set_ylabel('KS Test p-value')
        ax1.set_title('Kolmogorov-Smirnov Test Results\nby Dimension')
        ax1.set_xticks(dimensions)
        ax1.legend()
        
        # Add value labels on bars
        for bar, pvalue in zip(bars, ks_pvalues):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{pvalue:.3f}', ha='center', va='bottom')
        
        # AD test statistics across dimensions
        ad_stats = [result[0] for result in ad_results]
        
        bars = ax2.bar(dimensions, ad_stats, color='skyblue')
        ax2.set_xlabel('Dimension')
        ax2.set_ylabel('AD Test Statistic')
        ax2.set_title('Anderson-Darling Test Statistics\nby Dimension')
        ax2.set_xticks(dimensions)
        
        # Add value labels on bars
        for bar, stat in zip(bars, ad_stats):
            height = bar.get_height()
            ax2.text(bar.get_x() + bar.get_width()/2., height,
                    f'{stat:.3f}', ha='center', va='bottom')
        
        plt.tight_layout()
        if save_prefix:
            plt.savefig(f'{save_prefix}_test_summary.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        # Additional: Q-Q plots for each dimension
        fig, axes = plt.subplots(1, d, figsize=(5 * d, 5))
        if d == 1:
            axes = [axes]
        
        for i in range(d):
            # Sort data for Q-Q plot
            orig_sorted = np.sort(Y_orig[:, i])
            sim_sorted = np.sort(Y_sim[:, i])
            
            # Generate theoretical quantiles
            n_orig = len(orig_sorted)
            n_sim = len(sim_sorted)
            
            # Use smaller set for quantiles to avoid interpolation issues
            n_points = min(n_orig, n_sim, 1000)
            quantiles = np.linspace(0, 1, n_points)
            
            orig_quantiles = np.quantile(orig_sorted, quantiles)
            sim_quantiles = np.quantile(sim_sorted, quantiles)
            
            axes[i].plot(orig_quantiles, sim_quantiles, 'o', alpha=0.6, markersize=3)
            min_val = min(orig_quantiles.min(), sim_quantiles.min())
            max_val = max(orig_quantiles.max(), sim_quantiles.max())
            axes[i].plot([min_val, max_val], [min_val, max_val], 'r--', alpha=0.8, linewidth=2)
            axes[i].set_xlabel('Original Data Quantiles')
            axes[i].set_ylabel('Simulated Data Quantiles')
            axes[i].set_title(f'Dimension {i+1} - Q-Q Plot')
            
            # Add correlation coefficient
            corr = np.corrcoef(orig_quantiles, sim_quantiles)[0, 1]
            axes[i].text(0.05, 0.95, f'Corr: {corr:.4f}', transform=axes[i].transAxes,
                        bbox=dict(boxstyle="round,pad=0.3", facecolor="white", alpha=0.8),
                        verticalalignment='top')
        
        plt.tight_layout()
        if save_prefix:
            plt.savefig(f'{save_prefix}_qq_plots.png', dpi=300, bbox_inches='tight')
        plt.show()
        
        return {
            'ks_results': ks_results,
            'ad_results': ad_results,
            'dimensions': d
        }
